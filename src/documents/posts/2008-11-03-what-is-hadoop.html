---
layout: default
title: What Is Hadoop?
created: 1225741094
---
<p><a class="external" rel="nofollow" href="http://hadoop.apache.org/core/"><img height="11" width="11" src="http://wiki.apache.org/wiki/modern/img/moin-www.png" alt="[WWW]" /> Hadoop</a> is a framework for running applications on large clusters built of commodity hardware. The Hadoop framework transparently provides applications both reliability and data motion. Hadoop implements a computational paradigm named <a href="http://wiki.apache.org/hadoop/HadoopMapReduce"> Map/Reduce</a>, where the application is divided into many small fragments of work, each of which may be executed or reexecuted on any node in the cluster. In addition, it provides a distributed file system (<a href="http://wiki.apache.org/hadoop/DFS">HDFS</a>) that stores data on the compute nodes, providing very high aggregate bandwidth across the cluster. Both Map/Reduce and the distributed file system are designed so that node failures are automatically handled by the framework.</p>
